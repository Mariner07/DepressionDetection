{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Transformer.ipynb\"","provenance":[{"file_id":"https://github.com/prateekjoshi565/Fine-Tuning-BERT/blob/master/Fine_Tuning_BERT_for_Spam_Classification.ipynb","timestamp":1641419837068}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"OFOTiqrtNvyy"},"source":["# Install Transformers Library"]},{"cell_type":"code","metadata":{"id":"1hkhc10wNrGt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641516224954,"user_tz":-60,"elapsed":3979,"user":{"displayName":"nurlan nogoibaev","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04756131261594567033"}},"outputId":"cd0360d2-3b22-486f-9567-c9d8b13d7644"},"source":["!pip install --upgrade transformers==3.1.0"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers==3.1.0 in /usr/local/lib/python3.7/dist-packages (3.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (3.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (2019.12.20)\n","Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (0.8.1rc2)\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (0.1.96)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (4.62.3)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (0.0.46)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.1.0) (3.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (7.1.2)\n"]}]},{"cell_type":"code","source":["!python -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you, Come, Yating and petar!'))\"\n","# just to test if transformer imported\n","\n"],"metadata":{"id":"J2n4DDx4Ivo_","executionInfo":{"status":"ok","timestamp":1641516240631,"user_tz":-60,"elapsed":15681,"user":{"displayName":"nurlan nogoibaev","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04756131261594567033"}},"outputId":"293f4e9a-4ad0-4173-d698-5d8bdf97c32d","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading: 100% 629/629 [00:00<00:00, 522kB/s]\n","Downloading: 100% 232k/232k [00:00<00:00, 1.96MB/s]\n","Downloading: 100% 230/230 [00:00<00:00, 182kB/s]\n","Downloading: 100% 268M/268M [00:06<00:00, 40.9MB/s]\n","[{'label': 'POSITIVE', 'score': 0.9998518824577332}]\n"]}]},{"cell_type":"code","metadata":{"id":"x4giRzM7NtHJ"},"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","import transformers\n","from transformers import AutoModel, BertTokenizerFast\n","\n","# specify GPU\n","device = torch.device(\"cuda\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(np.__version__)"],"metadata":{"id":"NcWoaEmnLl3R","executionInfo":{"status":"ok","timestamp":1641516244716,"user_tz":-60,"elapsed":5,"user":{"displayName":"nurlan nogoibaev","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04756131261594567033"}},"outputId":"c7caf19e-62d9-47c1-8657-40084a5f8bf1","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1.19.5\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"5v3ULoFFST34"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kKd-Tj3hOMsZ"},"source":["# Load Dataset"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"HDdTaCt5MfL6","executionInfo":{"status":"ok","timestamp":1641516246569,"user_tz":-60,"elapsed":1856,"user":{"displayName":"nurlan nogoibaev","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04756131261594567033"}},"outputId":"f61510ff-0bd2-4bd5-941b-44cb5dafda03","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"cwJrQFQgN_BE","colab":{"base_uri":"https://localhost:8080/","height":591},"outputId":"a2060517-64c3-44af-c793-f044dcedde67","executionInfo":{"status":"ok","timestamp":1641516246570,"user_tz":-60,"elapsed":4,"user":{"displayName":"nurlan nogoibaev","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04756131261594567033"}}},"source":["df = pd.read_csv(\"/content/drive/MyDrive/DAIC-WOZ/clean_compiled_transcripts.csv\")\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-6fc230a5-ac4f-42b4-bf81-decfa991063d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Participant_ID</th>\n","      <th>Transcript</th>\n","      <th>PHQ8_Binary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>303</td>\n","      <td>okay bout california yeah oh well big broad lo...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>304</td>\n","      <td>good um los angeles california um cool weather...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>305</td>\n","      <td>alright uh originally california uh born glend...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>310</td>\n","      <td>yes okay fine live hollywood uh seattle uh kin...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>312</td>\n","      <td>yes fine yes weather weather mainly yeah main ...</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6fc230a5-ac4f-42b4-bf81-decfa991063d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6fc230a5-ac4f-42b4-bf81-decfa991063d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6fc230a5-ac4f-42b4-bf81-decfa991063d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   Participant_ID  ... PHQ8_Binary\n","0             303  ...         0.0\n","1             304  ...         0.0\n","2             305  ...         0.0\n","3             310  ...         0.0\n","4             312  ...         0.0\n","\n","[5 rows x 3 columns]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"fzPPOrVQWiW5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b5732321-70fc-4867-f096-29b7d00a1df0","executionInfo":{"status":"ok","timestamp":1641516246570,"user_tz":-60,"elapsed":3,"user":{"displayName":"nurlan nogoibaev","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04756131261594567033"}}},"source":["df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(141, 3)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"676DPU1BOPdp","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d5f0c4eb-8f1a-4c7d-91bf-873b28988064","executionInfo":{"status":"ok","timestamp":1641516246914,"user_tz":-60,"elapsed":346,"user":{"displayName":"nurlan nogoibaev","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04756131261594567033"}}},"source":["# check class distribution\n","df['PHQ8_Binary'].value_counts(normalize = True)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0    0.702128\n","1.0    0.297872\n","Name: PHQ8_Binary, dtype: float64"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"MKfWnApvOoE7"},"source":["# Split train dataset into train, validation and test sets"]},{"cell_type":"code","metadata":{"id":"mfhSPF5jOWb7"},"source":["train_text, val_text, train_labels, val_labels = train_test_split(df['Transcript'], df['PHQ8_Binary'], \n","                                                                    random_state=2018, \n","                                                                    test_size=0.3, \n","                                                                    stratify=df['PHQ8_Binary'])\n","\n","                                                            "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n7hsdLoCO7uB"},"source":["# Import BERT Model and BERT Tokenizer"]},{"cell_type":"code","metadata":{"id":"S1kY3gZjO2RE"},"source":["# import BERT-base pretrained model\n","bert = AutoModel.from_pretrained('bert-base-uncased')\n","\n","# Load the BERT tokenizer\n","tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_zOKeOMeO-DT"},"source":["# sample data\n","text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n","\n","# encode text\n","sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oAH73n39PHLw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"deae19ec-9632-459b-fdcc-ae6ba2d4b547","executionInfo":{"status":"ok","timestamp":1641516250119,"user_tz":-60,"elapsed":3,"user":{"displayName":"nurlan nogoibaev","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04756131261594567033"}}},"source":["# output\n","print(sent_id)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': [[101, 2023, 2003, 1037, 14324, 2944, 14924, 4818, 102, 0], [101, 2057, 2097, 2986, 1011, 8694, 1037, 14324, 2944, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"]}]},{"cell_type":"markdown","metadata":{"id":"8wIYaWI_Prg8"},"source":["# Tokenization"]},{"cell_type":"code","metadata":{"id":"yKwbpeN_PMiu","colab":{"base_uri":"https://localhost:8080/","height":282},"outputId":"33d2af12-358c-42a7-be38-2841c8932f76","executionInfo":{"status":"ok","timestamp":1641515937841,"user_tz":-60,"elapsed":574,"user":{"displayName":"nurlan nogoibaev","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04756131261594567033"}}},"source":["# get length of all the messages in the train set\n","seq_len = [len(i.split()) for i in train_text]\n","\n","pd.Series(seq_len).hist(bins = 30)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f61c0563890>"]},"metadata":{},"execution_count":26},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"OXcswEIRPvGe"},"source":["max_seq_len = 510\n","# average word length is ±500, so we take only 500 features and truncate the rest"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tk5S7DWaP2t6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641515940502,"user_tz":-60,"elapsed":228,"user":{"displayName":"nurlan nogoibaev","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04756131261594567033"}},"outputId":"87eb3fd5-504d-4267-83e5-c245df1f166a"},"source":["# tokenize and encode sequences in the training set\n","tokens_train = tokenizer.batch_encode_plus(\n","    train_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")\n","\n","# tokenize and encode sequences in the validation set\n","tokens_val = tokenizer.batch_encode_plus(\n","    val_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")\n","\n","# tokenize and encode sequences in the test set\n","# tokens_test = tokenizer.batch_encode_plus(\n","#     test_text.tolist(),\n","#     max_length = max_seq_len,\n","#     pad_to_max_length=True,\n","#     truncation=True,\n","#     return_token_type_ids=False\n","# )"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"markdown","metadata":{"id":"Wsm8bkRZQTw9"},"source":["# Convert Integer Sequences to Tensors"]},{"cell_type":"code","metadata":{"id":"QR-lXwmzQPd6"},"source":["# for train set\n","train_seq = torch.tensor(tokens_train['input_ids'])\n","train_mask = torch.tensor(tokens_train['attention_mask'])\n","train_y = torch.tensor(train_labels.tolist())\n","\n","# for validation set\n","val_seq = torch.tensor(tokens_val['input_ids'])\n","val_mask = torch.tensor(tokens_val['attention_mask'])\n","val_y = torch.tensor(val_labels.tolist())\n","\n","# # for test set\n","# test_seq = torch.tensor(tokens_test['input_ids'])\n","# test_mask = torch.tensor(tokens_test['attention_mask'])\n","# test_y = torch.tensor(test_labels.tolist())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ov1cOBlcRLuk"},"source":["# Create DataLoaders"]},{"cell_type":"code","metadata":{"id":"qUy9JKFYQYLp"},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","#define a batch size\n","batch_size = 32\n","\n","# wrap tensors\n","train_data = TensorDataset(train_seq, train_mask, train_y)\n","\n","# sampler for sampling the data during training\n","train_sampler = RandomSampler(train_data)\n","\n","# dataLoader for train set\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# wrap tensors\n","val_data = TensorDataset(val_seq, val_mask, val_y)\n","\n","# sampler for sampling the data during training\n","val_sampler = SequentialSampler(val_data)\n","\n","# dataLoader for validation set\n","val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K2HZc5ZYRV28"},"source":["# Freeze BERT Parameters"]},{"cell_type":"code","metadata":{"id":"wHZ0MC00RQA_"},"source":["# freeze all the parameters\n","for param in bert.parameters():\n","    param.requires_grad = False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s7ahGBUWRi3X"},"source":["# Define Model Architecture"]},{"cell_type":"code","metadata":{"id":"b3iEtGyYRd0A"},"source":["class BERT_Arch(nn.Module):\n","\n","    def __init__(self, bert):\n","      \n","      super(BERT_Arch, self).__init__()\n","\n","      self.bert = bert \n","      \n","      # dropout layer\n","      self.dropout = nn.Dropout(0.1)\n","      \n","      # relu activation function\n","      self.relu =  nn.ReLU()\n","\n","      # dense layer 1\n","      self.fc1 = nn.Linear(768,512)\n","      \n","      # dense layer 2 (Output layer)\n","      self.fc2 = nn.Linear(512,2)\n","\n","      #softmax activation function\n","      self.softmax = nn.LogSoftmax(dim=1)\n","\n","    #define the forward pass\n","    def forward(self, sent_id, mask):\n","\n","      #pass the inputs to the model  \n","      _, cls_hs = self.bert(sent_id, attention_mask=mask)\n","      \n","      x = self.fc1(cls_hs)\n","\n","      x = self.relu(x)\n","\n","      x = self.dropout(x)\n","\n","      # output layer\n","      x = self.fc2(x)\n","      \n","      # apply softmax activation\n","      x = self.softmax(x)\n","      # x=x.to(torch.int64)\n","\n","      return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cBAJJVuJRliv"},"source":["# pass the pre-trained BERT to our define architecture\n","model = BERT_Arch(bert)\n","\n","# push the model to GPU\n","model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"taXS0IilRn9J"},"source":["# optimizer from hugging face transformers\n","from transformers import AdamW\n","\n","# define the optimizer\n","optimizer = AdamW(model.parameters(), lr = 1e-3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j9CDpoMQR_rK"},"source":["# Find Class Weights"]},{"cell_type":"code","metadata":{"id":"izY5xH5eR7Ur","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fa4deae8-a709-4f56-e1d4-a6b5a118307d","executionInfo":{"status":"ok","timestamp":1641515952189,"user_tz":-60,"elapsed":8,"user":{"displayName":"nurlan nogoibaev","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04756131261594567033"}}},"source":["from sklearn.utils.class_weight import compute_class_weight\n","\n","#compute the class weights\n","class_wts = compute_class_weight(\n","    class_weight='balanced', \n","    classes= np.unique(train_labels), \n","    y=train_labels)\n","\n","print(class_wts)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.71014493 1.68965517]\n"]}]},{"cell_type":"code","metadata":{"id":"r1WvfY2vSGKi"},"source":["# convert class weights to tensor\n","weights= torch.tensor(class_wts,dtype=torch.float)\n","weights = weights.to(device)\n","\n","# loss function\n","cross_entropy  = nn.NLLLoss(weight=weights) \n","\n","# number of training epochs\n","epochs = 10"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"My4CA0qaShLq"},"source":["# Fine-Tune BERT"]},{"cell_type":"code","metadata":{"id":"rskLk8R_SahS"},"source":["# function to train the model\n","def train():\n","  \n","  model.train()\n","\n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save model predictions\n","  total_preds=[]\n","  \n","  # iterate over batches\n","  for step,batch in enumerate(train_dataloader):\n","    \n","    # progress update after every 50 batches.\n","    if step % 50 == 0 and not step == 0:\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [r.to(device) for r in batch]\n"," \n","    sent_id, mask, labels = batch\n","\n","    # clear previously calculated gradients \n","    model.zero_grad()        \n","\n","    # get model predictions for the current batch\n","    preds = model(sent_id, mask)\n","    labels=labels.to(torch.int64)\n","    # compute the loss between actual and predicted values\n","    loss = cross_entropy(preds, labels)\n","\n","    # add on to the total loss\n","    total_loss = total_loss + loss.item()\n","\n","    # backward pass to calculate the gradients\n","    loss.backward()\n","\n","    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","    # update parameters\n","    optimizer.step()\n","\n","    # model predictions are stored on GPU. So, push it to CPU\n","    preds=preds.detach().cpu().numpy()\n","\n","    # append the model predictions\n","    total_preds.append(preds)\n","\n","  # compute the training loss of the epoch\n","  avg_loss = total_loss / len(train_dataloader)\n","  \n","  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  #returns the loss and predictions\n","  return avg_loss, total_preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yGXovFDlSxB5"},"source":["# function for evaluating the model\n","def evaluate():\n","  \n","  print(\"\\nEvaluating...\")\n","  \n","  # deactivate dropout layers\n","  model.eval()\n","\n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save the model predictions\n","  total_preds = []\n","\n","  # iterate over batches\n","  for step,batch in enumerate(val_dataloader):\n","    \n","    # Progress update every 50 batches.\n","    if step % 50 == 0 and not step == 0:\n","      \n","      # Calculate elapsed time in minutes.\n","      elapsed = format_time(time.time() - t0)\n","            \n","      # Report progress.\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [t.to(device) for t in batch]\n","\n","    sent_id, mask, labels = batch\n","\n","    # deactivate autograd\n","    with torch.no_grad():\n","      \n","      # model predictions\n","      preds = model(sent_id, mask)\n","\n","      # compute the validation loss between actual and predicted values\n","      labels= labels.to(torch.int64)\n","      loss = cross_entropy(preds,labels)\n","\n","      total_loss = total_loss + loss.item()\n","\n","      preds = preds.detach().cpu().numpy()\n","\n","      total_preds.append(preds)\n","\n","  # compute the validation loss of the epoch\n","  avg_loss = total_loss / len(val_dataloader) \n","\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  return avg_loss, total_preds"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9KZEgxRRTLXG"},"source":["# Start Model Training"]},{"cell_type":"code","metadata":{"id":"k1USGTntS3TS","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"a36cf346-7806-4b42-9115-8d20a5bcbad1"},"source":["# set initial loss to infinite\n","best_valid_loss = float('inf')\n","\n","# empty lists to store training and validation loss of each epoch\n","train_losses=[]\n","valid_losses=[]\n","\n","#for each epoch\n","for epoch in range(13):\n","     \n","    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n","    \n","    #train model\n","    train_loss, _ = train()\n","    \n","    #evaluate model\n","    valid_loss, _ = evaluate()\n","    \n","    #save the best model\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'saved_weights.pt')\n","    \n","    # append training and validation loss\n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","    \n","    print(f'\\nTraining Loss: {train_loss:.3f}')\n","    print(f'Validation Loss: {valid_loss:.3f}')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," Epoch 1 / 10\n","\n","Evaluating...\n","\n","Training Loss: 0.852\n","Validation Loss: 0.686\n","\n"," Epoch 2 / 10\n","\n","Evaluating...\n","\n","Training Loss: 0.698\n","Validation Loss: 0.716\n","\n"," Epoch 3 / 10\n","\n","Evaluating...\n","\n","Training Loss: 0.733\n","Validation Loss: 0.707\n","\n"," Epoch 4 / 10\n","\n","Evaluating...\n","\n","Training Loss: 0.672\n","Validation Loss: 0.802\n","\n"," Epoch 5 / 10\n","\n","Evaluating...\n","\n","Training Loss: 0.707\n","Validation Loss: 0.708\n","\n"," Epoch 6 / 10\n","\n","Evaluating...\n","\n","Training Loss: 0.645\n","Validation Loss: 0.704\n","\n"," Epoch 7 / 10\n","\n","Evaluating...\n","\n","Training Loss: 0.719\n","Validation Loss: 0.695\n","\n"," Epoch 8 / 10\n","\n","Evaluating...\n","\n","Training Loss: 0.725\n","Validation Loss: 0.683\n","\n"," Epoch 9 / 10\n","\n","Evaluating...\n","\n","Training Loss: 0.701\n","Validation Loss: 0.677\n","\n"," Epoch 10 / 10\n","\n","Evaluating...\n","\n","Training Loss: 0.714\n","Validation Loss: 0.677\n","\n"," Epoch 11 / 10\n","\n","Evaluating...\n","\n","Training Loss: 0.660\n","Validation Loss: 0.717\n","\n"," Epoch 12 / 10\n","\n","Evaluating...\n","\n","Training Loss: 0.657\n","Validation Loss: 0.721\n","\n"," Epoch 13 / 10\n","\n","Evaluating...\n","\n","Training Loss: 0.666\n","Validation Loss: 0.690\n","\n"," Epoch 14 / 10\n","\n","Evaluating...\n","\n","Training Loss: 0.666\n","Validation Loss: 0.680\n","\n"," Epoch 15 / 10\n","\n","Evaluating...\n","\n","Training Loss: 0.670\n","Validation Loss: 0.678\n","\n"," Epoch 16 / 10\n","\n","Evaluating...\n","\n","Training Loss: 0.720\n","Validation Loss: 0.685\n","\n"," Epoch 17 / 10\n","\n","Evaluating...\n","\n","Training Loss: 0.680\n","Validation Loss: 0.683\n","\n"," Epoch 18 / 10\n","\n","Evaluating...\n","\n","Training Loss: 0.677\n","Validation Loss: 0.683\n","\n"," Epoch 19 / 10\n","\n","Evaluating...\n","\n","Training Loss: 0.706\n","Validation Loss: 0.681\n","\n"," Epoch 20 / 10\n","\n","Evaluating...\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-54d545d70808>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#save the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-38-6746aeaddc4f>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m       \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"_yrhUc9kTI5a"},"source":["# Load Saved Model"]},{"cell_type":"code","metadata":{"id":"OacxUyizS8d1","colab":{"base_uri":"https://localhost:8080/","height":198},"outputId":"ad53ff1d-50b4-4c6b-d641-46456ea67170","executionInfo":{"status":"error","timestamp":1641516175233,"user_tz":-60,"elapsed":209,"user":{"displayName":"nurlan nogoibaev","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04756131261594567033"}}},"source":["#load weights of best model\n","path = 'saved_weights.pt'\n","model.load_state_dict(torch.load(path))"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-5a29cc8ec3f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#load weights of best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'saved_weights.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"x4SVftkkTZXA"},"source":["# Get Predictions for Test Data"]},{"cell_type":"code","metadata":{"id":"NZl0SZmFTRQA","executionInfo":{"status":"error","timestamp":1641516198477,"user_tz":-60,"elapsed":215,"user":{"displayName":"nurlan nogoibaev","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04756131261594567033"}},"colab":{"base_uri":"https://localhost:8080/","height":215},"outputId":"4da3109f-e86f-4fb8-ffdf-bb36251c28b6"},"source":["# get predictions for test data\n","with torch.no_grad():\n","  preds = model(test_seq.to(device), test_mask.to(device))\n","  preds = preds.detach().cpu().numpy()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-3a253e0de617>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get predictions for test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"]}]},{"cell_type":"code","metadata":{"id":"Ms1ObHZxTYSI","colab":{"base_uri":"https://localhost:8080/","height":198},"outputId":"04097f40-6bc7-4e61-ee61-b81593bd439e","executionInfo":{"status":"error","timestamp":1641516198825,"user_tz":-60,"elapsed":3,"user":{"displayName":"nurlan nogoibaev","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04756131261594567033"}}},"source":["# model's performance\n","preds = np.argmax(preds, axis = 1)\n","print(classification_report(test_y, preds))"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-23a5cebbf86b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model's performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"]}]},{"cell_type":"code","metadata":{"id":"YqzLS7rHTp4T"},"source":["# confusion matrix\n","pd.crosstab(test_y, preds)"],"execution_count":null,"outputs":[]}]}

# DepressionDetection
##Project summary:
The project aimed at comparison of multimedia processing and machine learning methods for automatic audiovisual analysis of emotion and depression from the 
Avec 2019 competition [Database](https://drive.google.com/drive/folders/1w1zvscLanL8wKEm6fPvQBJ-pqRqe-fzH?usp=sharing). There are basically three data types: audio, image and text extracted from the videochat recprdings. The video chat recordings were annotated time-continuously in terms of the emotional dimensions arousal, valence, and liking, i. e., how much a subject expresses a positive or a negative attitude while speaking, either with respect to the commercial, the advertised product, or any other matters discussed. 

We used several data processing techniques required for each type of data and classified the depression status using models that varied from linear to transformers and neural nets. 

So far, we managed to ideally classify patients on depression independently for each data type, and the next step would be an integration of the models using embeddings, perhaps.

<img width="1031" alt="Снимок экрана 2022-01-19 в 04 28 14" src="https://user-images.githubusercontent.com/73485842/150058638-9d861a77-cdb1-43f0-8a16-82f01b97273d.png">
